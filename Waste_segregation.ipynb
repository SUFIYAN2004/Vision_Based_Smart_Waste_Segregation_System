{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wilELMekRn0u",
        "outputId": "fcbcee0b-15b7-429a-d3ca-302f44bb010f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Force Collecting All Data ---\n",
            "Using Colab cache for faster access to the 'waste-classification' dataset.\n",
            "✅ Found 1268 images for Recyclable\n",
            "✅ Found 651 images for Organic\n",
            "✅ Found 918 images for Hazardous\n",
            "\n",
            "--- Step 2: Building Organic-Focus Pipeline ---\n",
            "Found 2837 files belonging to 3 classes.\n",
            "Using 2270 files for training.\n",
            "Found 2837 files belonging to 3 classes.\n",
            "Using 567 files for validation.\n",
            "Applying Class Weights: {0: np.float64(1.0365296803652968), 1: np.float64(1.4607464607464606), 2: np.float64(0.7403783431180692)}\n",
            "\n",
            "--- Step 3: Building ResNet Architecture ---\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "--- Training Phase 1 ---\n",
            "Epoch 1/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 492ms/step - accuracy: 0.5545 - loss: 1.1039 - val_accuracy: 0.7566 - val_loss: 0.6137\n",
            "Epoch 2/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 487ms/step - accuracy: 0.7285 - loss: 0.6053 - val_accuracy: 0.7725 - val_loss: 0.5971\n",
            "Epoch 3/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 475ms/step - accuracy: 0.7836 - loss: 0.5238 - val_accuracy: 0.7760 - val_loss: 0.5773\n",
            "Epoch 4/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 485ms/step - accuracy: 0.7859 - loss: 0.5080 - val_accuracy: 0.7813 - val_loss: 0.5712\n",
            "Epoch 5/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 516ms/step - accuracy: 0.8025 - loss: 0.4555 - val_accuracy: 0.7725 - val_loss: 0.5814\n",
            "Epoch 6/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 480ms/step - accuracy: 0.8177 - loss: 0.4420 - val_accuracy: 0.8025 - val_loss: 0.5419\n",
            "Epoch 7/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 510ms/step - accuracy: 0.8320 - loss: 0.4277 - val_accuracy: 0.7937 - val_loss: 0.5498\n",
            "Epoch 8/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 519ms/step - accuracy: 0.8408 - loss: 0.3744 - val_accuracy: 0.7954 - val_loss: 0.5386\n",
            "Epoch 9/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 536ms/step - accuracy: 0.8509 - loss: 0.3598 - val_accuracy: 0.7919 - val_loss: 0.5604\n",
            "Epoch 10/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 511ms/step - accuracy: 0.8590 - loss: 0.3344 - val_accuracy: 0.8025 - val_loss: 0.5154\n",
            "Epoch 11/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 517ms/step - accuracy: 0.8674 - loss: 0.3174 - val_accuracy: 0.8007 - val_loss: 0.5374\n",
            "Epoch 12/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 476ms/step - accuracy: 0.8755 - loss: 0.2918 - val_accuracy: 0.8060 - val_loss: 0.5493\n",
            "Epoch 13/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 521ms/step - accuracy: 0.8837 - loss: 0.2743 - val_accuracy: 0.7866 - val_loss: 0.5641\n",
            "Epoch 14/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 459ms/step - accuracy: 0.8973 - loss: 0.2862 - val_accuracy: 0.7637 - val_loss: 0.6272\n",
            "Epoch 15/15\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 472ms/step - accuracy: 0.8908 - loss: 0.2719 - val_accuracy: 0.7901 - val_loss: 0.5528\n",
            "\n",
            "--- Training Phase 2: Unfreezing for Organic Texture ---\n",
            "Epoch 1/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 591ms/step - accuracy: 0.6703 - loss: 0.7764 - val_accuracy: 0.7601 - val_loss: 0.6109\n",
            "Epoch 2/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 567ms/step - accuracy: 0.7837 - loss: 0.5002 - val_accuracy: 0.7654 - val_loss: 0.5764\n",
            "Epoch 3/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 567ms/step - accuracy: 0.7956 - loss: 0.4750 - val_accuracy: 0.7866 - val_loss: 0.5596\n",
            "Epoch 4/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 606ms/step - accuracy: 0.8469 - loss: 0.4004 - val_accuracy: 0.7831 - val_loss: 0.5640\n",
            "Epoch 5/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 618ms/step - accuracy: 0.8585 - loss: 0.3630 - val_accuracy: 0.7848 - val_loss: 0.5590\n",
            "Epoch 6/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 564ms/step - accuracy: 0.8694 - loss: 0.3314 - val_accuracy: 0.7919 - val_loss: 0.5502\n",
            "Epoch 7/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 563ms/step - accuracy: 0.8616 - loss: 0.3245 - val_accuracy: 0.7919 - val_loss: 0.5525\n",
            "Epoch 8/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 563ms/step - accuracy: 0.8937 - loss: 0.2828 - val_accuracy: 0.7972 - val_loss: 0.5468\n",
            "Epoch 9/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 616ms/step - accuracy: 0.8883 - loss: 0.2854 - val_accuracy: 0.7919 - val_loss: 0.5507\n",
            "Epoch 10/10\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 562ms/step - accuracy: 0.9134 - loss: 0.2437 - val_accuracy: 0.7954 - val_loss: 0.5572\n",
            "\n",
            "--- DONE! Download 'waste_pro_final.keras' ---\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import os, shutil, pathlib\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# 1. CLEAN & COLLECT DATA\n",
        "print(\"--- Step 1: Force Collecting All Data ---\")\n",
        "src_path = kagglehub.dataset_download(\"phenomsg/waste-classification\")\n",
        "src_dir = pathlib.Path(src_path)\n",
        "dest_dir = pathlib.Path('/tmp/waste_pro_v5')\n",
        "\n",
        "if dest_dir.exists(): shutil.rmtree(dest_dir)\n",
        "dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "target_classes = ['Recyclable', 'Organic', 'Hazardous']\n",
        "for cls in target_classes:\n",
        "    target_cls_dir = dest_dir / cls\n",
        "    target_cls_dir.mkdir(exist_ok=True)\n",
        "    count = 0\n",
        "    for f in src_dir.rglob('*'):\n",
        "        if f.is_file() and f.suffix.lower() in ('.jpg', '.jpeg', '.png') and cls.lower() in str(f).lower():\n",
        "            try:\n",
        "                img_raw = tf.io.read_file(str(f))\n",
        "                tf.io.decode_image(img_raw)\n",
        "                shutil.copy(str(f), str(target_cls_dir / f\"{count}_{f.name}\"))\n",
        "                count += 1\n",
        "            except: continue\n",
        "    print(f\"✅ Found {count} images for {cls}\")\n",
        "\n",
        "# 2. PIPELINE WITH INTENSE AUGMENTATION\n",
        "print(\"\\n--- Step 2: Building Organic-Focus Pipeline ---\")\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dest_dir, validation_split=0.2, subset=\"training\", seed=123, image_size=(224, 224), batch_size=32\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    dest_dir, validation_split=0.2, subset=\"validation\", seed=123, image_size=(224, 224), batch_size=32\n",
        ")\n",
        "\n",
        "# HEAVY Augmentation to stop the model from being lazy\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomContrast(0.2), # Helps with Organic textures\n",
        "    layers.RandomBrightness(0.1)\n",
        "])\n",
        "\n",
        "# CALCULATE CLASS WEIGHTS (The Secret Fix)\n",
        "y_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = dict(enumerate(weights))\n",
        "print(f\"Applying Class Weights: {class_weights}\")\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 3. ARCHITECTURE: RESNET50V2 (Smarter than MobileNet)\n",
        "print(\"\\n--- Step 3: Building ResNet Architecture ---\")\n",
        "base_model = tf.keras.applications.ResNet50V2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(224, 224, 3)),\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 4. TRAINING WITH BALANCING\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True),\n",
        "    ModelCheckpoint('waste_pro_final.keras', monitor='val_accuracy', save_best_only=True)\n",
        "]\n",
        "\n",
        "print(\"\\n--- Training Phase 1 ---\")\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=15, class_weight=class_weights, callbacks=callbacks)\n",
        "\n",
        "print(\"\\n--- Training Phase 2: Unfreezing for Organic Texture ---\")\n",
        "base_model.trainable = True # Fully unfreeze\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=10, class_weight=class_weights, callbacks=callbacks)\n",
        "\n",
        "print(\"\\n--- DONE! Download 'waste_pro_final.keras' ---\")"
      ]
    }
  ]
}